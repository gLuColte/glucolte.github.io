<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Large Language Models (LLMs) · glucolte</title>
  <meta name="description" content="notes • principles • systems">
  <link rel="stylesheet" href="/assets/style.css">
  <link rel="stylesheet" href="/assets/study.css">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/favicon.png">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Large Language Models (LLMs) | glucolte</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Large Language Models (LLMs)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="notes • principles • systems" />
<meta property="og:description" content="notes • principles • systems" />
<link rel="canonical" href="http://localhost:4000/study/aiLLMs" />
<meta property="og:url" content="http://localhost:4000/study/aiLLMs" />
<meta property="og:site_name" content="glucolte" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Large Language Models (LLMs)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"notes • principles • systems","headline":"Large Language Models (LLMs)","url":"http://localhost:4000/study/aiLLMs"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
  <header class="site-header">
  <a class="brand" href="/">glucolte</a>
  <nav class="nav">
    <a href="/principles">principles</a>
    <a href="/rules">rules</a>
    <a href="/stretches">stretches</a>
    <a href="/study/">study</a>
    <a href="/projects/">projects</a>
    <a href="/setup/">setup</a>
  </nav>
  <button id="dark-mode-toggle" class="dark-mode-toggle" aria-label="Toggle dark mode">
    <svg class="sun-icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
    <svg class="moon-icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
    </svg>
  </button>
</header>


  <main class="container">
    <article class="content">
      <h1 id="large-language-models-llms">Large Language Models (LLMs)</h1>

<h2 id="1-introduction-to-llms">1. Introduction to LLMs</h2>
<p>LLMs are giant neural networks trained on massive amounts of text — the internet, books, articles, code — to learn how language works. They don’t “understand” words in the human sense; instead, they learn patterns and relationships between words, and then predict what comes next. It sounds simple, but when scaled up to trillions of parameters, that prediction process starts to look a lot like reasoning, creativity, and understanding.</p>

<hr />

<h2 id="2-how-llms-work">2. How LLMs Work</h2>
<p>The secret sauce behind modern LLMs is something called the <strong>Transformer</strong> architecture.<br />
Instead of processing words one by one like older models did, Transformers look at entire sequences at once and figure out which words matter most in a given context — a process known as <em>self-attention</em>.</p>

<p>When you type a sentence, the model breaks it down into small chunks called <em>tokens</em> — kind of like syllables for computers.<br />
Each token is turned into a vector (a list of numbers) that represents meaning. The model then predicts the next token, again and again, until it forms a complete thought.</p>

<p>During training, the LLM reads billions of examples and learns statistical relationships between words.<br />
So when you ask, “Why is the sky blue?”, it doesn’t search the internet — it generates an answer by combining everything it has learned about “why,” “sky,” and “blue” into something coherent and probable.<br />
That’s why it sometimes feels eerily human — but also why it can still make mistakes: it’s guessing, not knowing.</p>

<hr />

<h2 id="3-llms-vs-chatbots">3. LLMs vs. Chatbots</h2>
<p>For a long time, I thought ChatGPT <em>was</em> the model itself — but it turns out that’s not quite true.<br />
A <strong>chatbot</strong> like ChatGPT or Claude.ai is an application layer that sits on top of the raw model (like GPT-4 or Claude 3).</p>

<p>The LLM is the brain — it does the thinking, the reasoning, and the language generation.<br />
The chatbot is more like the personality and memory system that helps us talk to that brain in a friendly way.<br />
It adds rules, safety filters, a conversational interface, and sometimes memory so it can remember past messages.</p>

<p>So if you imagine an LLM as a powerful engine, a chatbot is the car built around it — with safety features, seats, and a nice dashboard.</p>

<table class="study-table">
  <thead>
    <tr>
      <th>Concept</th>
      <th>LLM</th>
      <th>Chatbot</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>What it is</td>
      <td>The trained AI model</td>
      <td>The app using the model</td>
    </tr>
    <tr>
      <td>Purpose</td>
      <td>Understands and generates text</td>
      <td>Interacts naturally with users</td>
    </tr>
    <tr>
      <td>Example</td>
      <td>GPT-4, Claude, Gemini</td>
      <td>ChatGPT, Claude.ai, Gemini App</td>
    </tr>
    <tr>
      <td>Analogy</td>
      <td>Engine</td>
      <td>Car</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="4-major-llm-families">4. Major LLM Families</h2>
<p>Once you start looking deeper, you realize there isn’t just <em>one</em> LLM — there are many, each created by different companies with their own goals and philosophies.</p>

<table class="study-table">
  <thead>
    <tr>
      <th>Company</th>
      <th>Model Line</th>
      <th>Example Products</th>
      <th>What makes it unique</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>OpenAI</strong></td>
      <td>GPT series</td>
      <td>ChatGPT, API</td>
      <td>Known for reasoning, creativity, and consistent quality.</td>
    </tr>
    <tr>
      <td><strong>Anthropic</strong></td>
      <td>Claude</td>
      <td>Claude.ai</td>
      <td>Built around “Constitutional AI,” prioritizing safety and helpfulness.</td>
    </tr>
    <tr>
      <td><strong>Google DeepMind</strong></td>
      <td>Gemini</td>
      <td>Gemini App, Workspace AI</td>
      <td>Designed to handle text, images, and code (multimodal).</td>
    </tr>
    <tr>
      <td><strong>Meta</strong></td>
      <td>LLaMA</td>
      <td>Open-weight models</td>
      <td>Open-source, community-driven, developer-friendly.</td>
    </tr>
    <tr>
      <td><strong>Mistral</strong></td>
      <td>Mistral / Mixtral</td>
      <td>Hugging Face, Ollama</td>
      <td>Small but powerful; optimized for local inference.</td>
    </tr>
    <tr>
      <td><strong>AWS</strong></td>
      <td>Nova</td>
      <td>Amazon Bedrock</td>
      <td>Cloud-integrated, made for enterprise workloads.</td>
    </tr>
    <tr>
      <td><strong>xAI</strong></td>
      <td>Grok</td>
      <td>X (Twitter)</td>
      <td>Uses live social data; witty, personality-driven tone.</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="5-architectural--training-differences">5. Architectural &amp; Training Differences</h2>
<p>Even though most of these models share the Transformer architecture, they differ in subtle but important ways.<br />
Some use <strong>decoder-only</strong> structures (like GPT-4 and Claude), while others mix in <strong>Mixture-of-Experts (MoE)</strong> layers to make training more efficient.</p>

<p>They also vary in <strong>context length</strong> — how much text the model can keep in “memory” at once.<br />
Older models could handle maybe a few thousand tokens, but newer ones like Gemini and Claude can handle entire books.</p>

<p>Another big difference is <strong>multimodality</strong> — the ability to process not just text, but also images, code, audio, and even video.<br />
Lastly, training philosophies differ — from OpenAI’s <em>RLHF</em> to Anthropic’s <em>Constitutional AI</em>.<br />
These choices influence how models behave, how safe they are, and what they’re best at.</p>

<hr />

<h2 id="6-open-vs-closed-models">6. Open vs. Closed Models</h2>
<p>One of the biggest divides in the LLM world is between <strong>open-source</strong> and <strong>closed-source</strong> models.<br />
Open models like <strong>LLaMA</strong> and <strong>Mistral</strong> can be downloaded, customized, and even fine-tuned for personal use.<br />
Closed models like <strong>GPT-4</strong>, <strong>Claude</strong>, or <strong>Gemini</strong> are API-only — powerful and stable, but less transparent.</p>

<table class="study-table">
  <thead>
    <tr>
      <th>Type</th>
      <th>Examples</th>
      <th>Pros</th>
      <th>Cons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Open-source</strong></td>
      <td>LLaMA, Mistral</td>
      <td>Customizable, local control, transparent</td>
      <td>Requires setup, hardware, and tuning</td>
    </tr>
    <tr>
      <td><strong>Closed-source</strong></td>
      <td>GPT-4, Claude, Gemini</td>
      <td>Stable, production-ready, easy to integrate</td>
      <td>Opaque, vendor lock-in</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="7-ecosystem--usage">7. Ecosystem &amp; Usage</h2>
<p>LLMs don’t exist in isolation — they live in entire ecosystems.<br />
Developers use them through APIs (like OpenAI, Anthropic, Vertex AI, or Bedrock), or run smaller open models locally through <strong>Ollama</strong>, <strong>Hugging Face</strong>, or <strong>LM Studio</strong>.</p>

<p>Frameworks like <strong>LangChain</strong>, <strong>vLLM</strong>, and <strong>LlamaIndex</strong> make it easier to connect LLMs to data sources or tools, enabling features like memory, retrieval, and reasoning.<br />
This is where <strong>RAG (Retrieval-Augmented Generation)</strong> comes in — letting the model “look things up” instead of guessing.<br />
It’s not just about the model anymore; it’s about how we <em>use</em> it in a system.</p>

<hr />

<h2 id="8-comparison-summary">8. Comparison Summary</h2>
<p>Here’s a snapshot of the current LLM landscape:</p>

<table class="study-table">
  <thead>
    <tr>
      <th>Feature</th>
      <th>GPT-4 / o1</th>
      <th>Claude 3.5</th>
      <th>Gemini 1.5</th>
      <th>Nova (AWS)</th>
      <th>LLaMA 3</th>
      <th>Mistral</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Architecture</td>
      <td>Transformer (decoder-only)</td>
      <td>Constitutional AI</td>
      <td>Multimodal</td>
      <td>Bedrock-native</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
    <tr>
      <td>Context Length</td>
      <td>128k–1M</td>
      <td>200k+</td>
      <td>1M</td>
      <td>200k</td>
      <td>Variable</td>
      <td>Variable</td>
    </tr>
    <tr>
      <td>Handles Images</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>✅</td>
      <td>❌</td>
      <td>❌</td>
    </tr>
    <tr>
      <td>Open Source</td>
      <td>❌</td>
      <td>❌</td>
      <td>❌</td>
      <td>❌</td>
      <td>✅</td>
      <td>✅</td>
    </tr>
    <tr>
      <td>Typical Use</td>
      <td>Reasoning, creativity</td>
      <td>Ethics, alignment</td>
      <td>Multimodal tasks</td>
      <td>Enterprise AI</td>
      <td>Local dev</td>
      <td>Lightweight AI</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="9-future-trends">9. Future Trends</h2>
<p>LLMs are evolving fast — and they’re not stopping at text.<br />
The next generation of models is becoming <strong>multimodal</strong>, meaning they can understand and generate across text, image, audio, and even video.<br />
We’re also seeing <strong>on-device inference</strong>, where models run locally instead of in the cloud, and <strong>agentic behavior</strong>, where they can take actions or use tools.</p>

<p>Meanwhile, open-source models are catching up rapidly, closing the gap with proprietary giants.<br />
It’s fascinating to think that not long ago, “AI writing” was just science fiction — and now it’s something we can experiment with, learn from, and even build upon ourselves.</p>

    </article>
  </main>

  <div id="imageModal" class="image-modal">
  <div class="modal-content">
    <span class="modal-close">&times;</span>
    <button class="modal-nav modal-prev">&#8249;</button>
    <button class="modal-nav modal-next">&#8250;</button>
    <img id="modalImage" src="" alt="">
    <div id="modalCaption"></div>
  </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', () => {
  const modal = document.getElementById('imageModal');
  const modalImg = document.getElementById('modalImage');
  const modalCaption = document.getElementById('modalCaption');
  const modalClose = document.querySelector('.modal-close');
  const modalPrev = document.querySelector('.modal-prev');
  const modalNext = document.querySelector('.modal-next');

  const SCALE_STEP = 0.2;
  const MIN_SCALE = 1;
  const MAX_SCALE = 3;

  let modalImages = [];
  let currentIndex = -1;
  let currentScale = MIN_SCALE;
  let translateX = 0;
  let translateY = 0;
  let isDragging = false;
  let isTouchDragging = false;
  let isPinching = false;
  let dragStartX = 0;
  let dragStartY = 0;
  let pinchStartDistance = 0;
  let pinchStartScale = MIN_SCALE;
  let transitionTimeout;

  function refreshModalImages() {
    modalImages = Array.from(document.querySelectorAll('.modal-trigger'));
  }

  function applyTransform(withTransition = false) {
    if (currentScale <= MIN_SCALE) {
      currentScale = MIN_SCALE;
      translateX = 0;
      translateY = 0;
    }

    if (transitionTimeout) {
      clearTimeout(transitionTimeout);
      transitionTimeout = null;
    }

    modalImg.style.transition = withTransition ? 'transform 0.15s ease' : 'none';
    modalImg.style.transform = `translate(${translateX}px, ${translateY}px) scale(${currentScale})`;
    modalImg.style.cursor = currentScale > MIN_SCALE
      ? (isDragging || isTouchDragging ? 'grabbing' : 'grab')
      : 'auto';

    if (withTransition) {
      transitionTimeout = setTimeout(() => {
        modalImg.style.transition = 'none';
      }, 160);
    }
  }

  function resetTransform() {
    currentScale = MIN_SCALE;
    translateX = 0;
    translateY = 0;
    applyTransform(false);
  }

  function getDistance(touch1, touch2) {
    return Math.hypot(
      touch1.clientX - touch2.clientX,
      touch1.clientY - touch2.clientY
    );
  }

  function openModalAtIndex(index) {
    refreshModalImages();

    if (!modalImages.length) {
      return;
    }

    if (index < 0) {
      index = modalImages.length - 1;
    } else if (index >= modalImages.length) {
      index = 0;
    }

    const target = modalImages[index];
    if (!target) {
      return;
    }

    currentIndex = index;
    const src = target.dataset.modalSrc || target.src;
    const caption = target.getAttribute('data-caption') || target.alt;

    modalImg.src = src;
    modalCaption.textContent = caption || '';
    modal.classList.add('show');
    document.body.style.overflow = 'hidden';
    resetTransform();
  }

  function closeModal() {
    if (!modal.classList.contains('show')) {
      return;
    }
    modal.classList.remove('show');
    document.body.style.overflow = '';
    currentIndex = -1;
    isDragging = false;
    isTouchDragging = false;
    isPinching = false;
    resetTransform();
  }

  refreshModalImages();

  modalImg.addEventListener('dragstart', event => event.preventDefault());

  document.addEventListener('click', event => {
    const trigger = event.target.closest('.modal-trigger');
    if (!trigger) {
      return;
    }

    event.preventDefault();
    refreshModalImages();
    const index = modalImages.indexOf(trigger);
    openModalAtIndex(index > -1 ? index : 0);
  });

  modalClose?.addEventListener('click', closeModal);

  modal.addEventListener('click', event => {
    if (event.target === modal) {
      closeModal();
    }
  });

  document.addEventListener('keydown', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    switch (event.key) {
      case 'Escape':
        closeModal();
        break;
      case 'ArrowLeft':
        event.preventDefault();
        openModalAtIndex(currentIndex - 1);
        break;
      case 'ArrowRight':
        event.preventDefault();
        openModalAtIndex(currentIndex + 1);
        break;
      case '+':
      case '=':
        event.preventDefault();
        currentScale = Math.min(MAX_SCALE, currentScale + SCALE_STEP);
        applyTransform(true);
        break;
      case '-':
        event.preventDefault();
        currentScale = Math.max(MIN_SCALE, currentScale - SCALE_STEP);
        applyTransform(true);
        break;
      case '0':
        event.preventDefault();
        resetTransform();
        applyTransform(true);
        break;
      default:
        break;
    }
  });

  modal.addEventListener('wheel', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    event.preventDefault();
    const delta = event.deltaY > 0 ? -SCALE_STEP : SCALE_STEP;
    const nextScale = Math.max(MIN_SCALE, Math.min(MAX_SCALE, currentScale + delta));

    if (nextScale === currentScale) {
      return;
    }

    currentScale = nextScale;
    applyTransform(true);
  }, { passive: false });

  if (modalPrev) {
    modalPrev.addEventListener('click', event => {
      event.preventDefault();
      if (currentIndex === -1) {
        return;
      }
      openModalAtIndex(currentIndex - 1);
    });
  }

  if (modalNext) {
    modalNext.addEventListener('click', event => {
      event.preventDefault();
      if (currentIndex === -1) {
        return;
      }
      openModalAtIndex(currentIndex + 1);
    });
  }

  modalImg.addEventListener('mousedown', event => {
    if (!modal.classList.contains('show') || currentScale <= MIN_SCALE) {
      return;
    }

    event.preventDefault();
    isDragging = true;
    dragStartX = event.clientX;
    dragStartY = event.clientY;
    modalImg.style.cursor = 'grabbing';
  });

  document.addEventListener('mousemove', event => {
    if (!isDragging) {
      return;
    }

    event.preventDefault();
    translateX += event.clientX - dragStartX;
    translateY += event.clientY - dragStartY;
    dragStartX = event.clientX;
    dragStartY = event.clientY;
    applyTransform(false);
  });

  document.addEventListener('mouseup', () => {
    if (!isDragging) {
      return;
    }
    isDragging = false;
    modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
  });

  modalImg.addEventListener('touchstart', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.touches.length === 1 && currentScale > MIN_SCALE) {
      event.preventDefault();
      isTouchDragging = true;
      dragStartX = event.touches[0].clientX;
      dragStartY = event.touches[0].clientY;
      modalImg.style.cursor = 'grabbing';
    } else if (event.touches.length === 2) {
      event.preventDefault();
      isTouchDragging = false;
      isPinching = true;
      pinchStartDistance = getDistance(event.touches[0], event.touches[1]);
      pinchStartScale = currentScale;
      modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
    }
  }, { passive: false });

  modalImg.addEventListener('touchmove', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (isPinching && event.touches.length === 2) {
      event.preventDefault();
      const distance = getDistance(event.touches[0], event.touches[1]);
      if (pinchStartDistance > 0) {
        const scaleRatio = distance / pinchStartDistance;
        currentScale = Math.max(MIN_SCALE, Math.min(MAX_SCALE, pinchStartScale * scaleRatio));
        applyTransform(false);
      }
    } else if (isTouchDragging && event.touches.length === 1) {
      event.preventDefault();
      translateX += event.touches[0].clientX - dragStartX;
      translateY += event.touches[0].clientY - dragStartY;
      dragStartX = event.touches[0].clientX;
      dragStartY = event.touches[0].clientY;
      applyTransform(false);
    }
  }, { passive: false });

  modalImg.addEventListener('touchend', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.touches.length === 0) {
      isTouchDragging = false;
      modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
    }

    if (event.touches.length < 2) {
      isPinching = false;
      pinchStartDistance = 0;
      pinchStartScale = currentScale;
    }
  });

  modalImg.addEventListener('touchcancel', () => {
    if (!modal.classList.contains('show')) {
      return;
    }

    isTouchDragging = false;
    isPinching = false;
    pinchStartDistance = 0;
    pinchStartScale = currentScale;
    modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
  });

  modal.addEventListener('touchend', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.target === modal && event.changedTouches.length === 1 && !isTouchDragging && !isPinching) {
      closeModal();
    }
  }, { passive: true });
});
</script>

<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('[data-snippet-id]').forEach(caption => {
    const snippetId = caption.getAttribute('data-snippet-id');
    const snippetElement = document.getElementById(snippetId);

    if (snippetElement) {
      const content = snippetElement.textContent.replace(/"/g, '&quot;');
      caption.setAttribute('data-tooltip', content);
      caption.classList.add('diagram-caption');
    }
  });
});
</script>


  <!-- Floating Table of Contents -->
  <div id="floating-toc" class="floating-toc">
    <div class="toc-icon">
      <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <line x1="8" y1="6" x2="21" y2="6"></line>
        <line x1="8" y1="12" x2="21" y2="12"></line>
        <line x1="8" y1="18" x2="21" y2="18"></line>
        <line x1="3" y1="6" x2="3.01" y2="6"></line>
        <line x1="3" y1="12" x2="3.01" y2="12"></line>
        <line x1="3" y1="18" x2="3.01" y2="18"></line>
      </svg>
    </div>
    <div class="toc-content">
      <div class="toc-header">
        <span>Contents</span>
        <button class="toc-close" aria-label="Close table of contents">
          <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <line x1="18" y1="6" x2="6" y2="18"></line>
            <line x1="6" y1="6" x2="18" y2="18"></line>
          </svg>
        </button>
      </div>
      <nav class="toc-nav" id="toc-nav">
        <!-- Generated by JavaScript -->
      </nav>
    </div>
  </div>

  <footer class="site-footer">
    <span>© 2025 glucolte • </span>
    <a href="https://github.com/gLuColte/glucolte.github.io">source</a>
  </footer>

  <script>
    // Dark mode functionality
    function initDarkMode() {
      const toggle = document.getElementById('dark-mode-toggle');
      const body = document.body;
      
      // Check for saved theme preference or default to light mode
      const savedTheme = localStorage.getItem('theme');
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      
      if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
        body.setAttribute('data-theme', 'dark');
      }
      
      // Toggle dark mode
      if (toggle) {
        toggle.addEventListener('click', function() {
          const currentTheme = body.getAttribute('data-theme');
          const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
          
          body.setAttribute('data-theme', newTheme);
          localStorage.setItem('theme', newTheme);
        });
      }
    }
    
    // Initialize dark mode immediately to prevent flash
    initDarkMode();
    
    // Initialize highlight.js and floating TOC after the DOM is loaded
    document.addEventListener('DOMContentLoaded', function() {
      hljs.highlightAll();
      
      // Floating TOC functionality - only show on sub-study pages
      const floatingToc = document.getElementById('floating-toc');
      const tocNav = document.getElementById('toc-nav');
      const tocClose = document.querySelector('.toc-close');
      
      // Check if we're on a sub-study page (not the main study index)
      const isSubStudyPage = window.location.pathname !== '/study/' && 
                            window.location.pathname !== '/study' && 
                            window.location.pathname.startsWith('/study/');
      
      if (floatingToc && tocNav && isSubStudyPage) {
        // Generate TOC from headings
        function generateTOC() {
          const headings = document.querySelectorAll('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6');
          if (headings.length === 0) {
            floatingToc.style.display = 'none';
            return;
          }
          
          const tocList = document.createElement('ul');
          let currentLevel = 0;
          let currentList = tocList;
          const listStack = [tocList];
          
          headings.forEach((heading, index) => {
            const level = parseInt(heading.tagName.charAt(1));
            const id = heading.id || `heading-${index}`;
            
            // Ensure heading has an ID
            if (!heading.id) {
              heading.id = id;
            }
            
            // Create list item
            const listItem = document.createElement('li');
            const link = document.createElement('a');
            link.href = `#${id}`;
            link.textContent = heading.textContent.trim();
            link.addEventListener('click', function(e) {
              e.preventDefault();
              const targetElement = document.getElementById(id);
              if (targetElement) {
                targetElement.scrollIntoView({ behavior: 'smooth', block: 'start' });
                // Close TOC after clicking
                floatingToc.classList.remove('toc-open');
              }
            });
            
            listItem.appendChild(link);
            
            // Handle nesting
            if (level > currentLevel) {
              // Go deeper
              for (let i = currentLevel; i < level; i++) {
                const newList = document.createElement('ul');
                currentList.appendChild(newList);
                listStack.push(newList);
                currentList = newList;
              }
            } else if (level < currentLevel) {
              // Go shallower
              for (let i = currentLevel; i > level; i--) {
                listStack.pop();
                currentList = listStack[listStack.length - 1];
              }
            }
            
            currentList.appendChild(listItem);
            currentLevel = level;
          });
          
          tocNav.appendChild(tocList);
        }
        
        // Generate the TOC
        generateTOC();
        
        // Handle close button
        if (tocClose) {
          tocClose.addEventListener('click', function() {
            floatingToc.classList.remove('toc-open');
          });
        }
        
        // Handle click on icon to toggle
        const tocIcon = document.querySelector('.toc-icon');
        if (tocIcon) {
          tocIcon.addEventListener('click', function() {
            floatingToc.classList.toggle('toc-open');
          });
        }
        
        // Active section highlighting
        function updateActiveSection() {
          const headings = document.querySelectorAll('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6');
          const tocLinks = tocNav.querySelectorAll('a');
          
          // Remove active class from all links
          tocLinks.forEach(link => link.classList.remove('active'));
          
          // Find the current section
          let currentHeading = null;
          const scrollPosition = window.scrollY + 100; // Offset for better UX
          
          for (let i = headings.length - 1; i >= 0; i--) {
            const heading = headings[i];
            const headingTop = heading.offsetTop;
            
            if (headingTop <= scrollPosition) {
              currentHeading = heading;
              break;
            }
          }
          
          // Add active class to current section
          if (currentHeading) {
            const activeLink = tocNav.querySelector(`a[href="#${currentHeading.id}"]`);
            if (activeLink) {
              activeLink.classList.add('active');
            }
          }
        }
        
        // Update active section on scroll
        let scrollTimeout;
        window.addEventListener('scroll', function() {
          if (scrollTimeout) {
            clearTimeout(scrollTimeout);
          }
          scrollTimeout = setTimeout(updateActiveSection, 10);
        });
        
        // Initial update
        updateActiveSection();
      } else if (floatingToc && !isSubStudyPage) {
        // Hide floating TOC on main study page
        floatingToc.style.display = 'none';
      }
      
      // Legacy TOC functionality (for existing markdown TOCs)
      const toc = document.querySelector('#markdown-toc');
      if (toc) {
        // Hide the floating TOC if there's already a markdown TOC
        if (floatingToc) {
          floatingToc.style.display = 'none';
        }
        
        // Create TOC container with header
        const tocContainer = document.createElement('div');
        tocContainer.className = 'toc-container';
        tocContainer.style.cssText = `
          background: #f8fafc;
          border: 1px solid #e5e7eb;
          border-radius: 8px;
          padding: 16px;
          margin: 20px 0;
          position: relative;
        `;
        
        // Add TOC header
        const tocHeader = document.createElement('h3');
        tocHeader.textContent = 'Table of Contents';
        tocHeader.style.cssText = `
          margin: 0 0 12px 0;
          font-size: 16px;
          font-weight: 600;
          color: #374151;
        `;
        
        // Add back to top button
        const backToTopBtn = document.createElement('button');
        backToTopBtn.textContent = '↑ Top';
        backToTopBtn.style.cssText = `
          position: absolute;
          top: 12px;
          right: 12px;
          background: #ffffff;
          border: 1px solid #d1d5db;
          border-radius: 6px;
          padding: 4px 8px;
          font-size: 12px;
          cursor: pointer;
          color: #6b7280;
          transition: all 0.2s ease;
        `;
        
        // Add hover effect for back to top button
        backToTopBtn.addEventListener('mouseenter', function() {
          this.style.background = '#f3f4f6';
          this.style.color = '#374151';
        });
        
        backToTopBtn.addEventListener('mouseleave', function() {
          this.style.background = '#ffffff';
          this.style.color = '#6b7280';
        });
        
        // Back to top functionality
        backToTopBtn.addEventListener('click', function() {
          window.scrollTo({ top: 0, behavior: 'smooth' });
        });
        
        // Style the TOC list
        toc.style.cssText = `
          margin: 0;
          padding: 0;
          font-size: 14px;
          line-height: 1.5;
        `;
        
        // Insert header and button into container
        tocContainer.appendChild(tocHeader);
        tocContainer.appendChild(backToTopBtn);
        tocContainer.appendChild(toc);
        
        // Replace the original TOC with the new container
        toc.parentNode.insertBefore(tocContainer, toc);
        tocContainer.appendChild(toc);
        
        // Add smooth scrolling to TOC links
        const tocLinks = toc.querySelectorAll('a');
        tocLinks.forEach(link => {
          link.addEventListener('click', function(e) {
            e.preventDefault();
            const targetId = this.getAttribute('href').substring(1);
            const targetElement = document.getElementById(targetId);
            if (targetElement) {
              targetElement.scrollIntoView({ behavior: 'smooth' });
            }
          });
        });
      }
    });
  </script>
</body>
</html>
