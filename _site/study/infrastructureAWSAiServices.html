<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>AWS AI Services · glucolte</title>
  <meta name="description" content="notes • principles • systems">
  <link rel="stylesheet" href="/assets/style.css">
  <link rel="stylesheet" href="/assets/study.css">
  <link rel="icon" type="image/svg+xml" href="/favicon.svg">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/favicon.png">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>AWS AI Services | glucolte</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="AWS AI Services" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="notes • principles • systems" />
<meta property="og:description" content="notes • principles • systems" />
<link rel="canonical" href="http://localhost:4000/study/infrastructureAWSAiServices" />
<meta property="og:url" content="http://localhost:4000/study/infrastructureAWSAiServices" />
<meta property="og:site_name" content="glucolte" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="AWS AI Services" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"notes • principles • systems","headline":"AWS AI Services","url":"http://localhost:4000/study/infrastructureAWSAiServices"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>
  <header class="site-header">
  <a class="brand" href="/">glucolte</a>
  <nav class="nav">
    <a href="/principles">principles</a>
    <a href="/rules">rules</a>
    <a href="/stretches">stretches</a>
    <a href="/study/">study</a>
    <a href="/projects/">projects</a>
    <a href="/setup/">setup</a>
  </nav>
  <button id="dark-mode-toggle" class="dark-mode-toggle" aria-label="Toggle dark mode">
    <svg class="sun-icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
    <svg class="moon-icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
      <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
    </svg>
  </button>
</header>


  <main class="container">
    <article class="content">
      <p>Foundation Model vs LLM</p>
<table class="study-table">
  <thead>
    <tr>
      <th>Dimension</th>
      <th>Foundation Model</th>
      <th>Large Language Model (LLM)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Definition</strong></td>
      <td>A large, general-purpose model trained on broad data that can be adapted to many tasks</td>
      <td>A foundation model specialized in language (text / tokens)</td>
    </tr>
    <tr>
      <td><strong>Scope</strong></td>
      <td>Multimodal or single-modal (text, image, audio, video, code)</td>
      <td>Language-focused (text, code, sometimes multimodal extensions)</td>
    </tr>
    <tr>
      <td><strong>Input / Output</strong></td>
      <td>Text, images, audio, video, embeddings</td>
      <td>Tokens (text / code), sometimes images via adapters</td>
    </tr>
    <tr>
      <td><strong>Core Objective</strong></td>
      <td>Learn general representations</td>
      <td>Learn next-token prediction in language</td>
    </tr>
    <tr>
      <td><strong>Training Data</strong></td>
      <td>Massive, diverse, often multimodal</td>
      <td>Massive text and code corpora</td>
    </tr>
    <tr>
      <td><strong>Training Task</strong></td>
      <td>Self-supervised learning (varies by modality)</td>
      <td>Autoregressive next-token prediction</td>
    </tr>
    <tr>
      <td><strong>Adaptation</strong></td>
      <td>Fine-tuning, adapters, prompting, RLHF</td>
      <td>Prompting, instruction tuning, RLHF</td>
    </tr>
    <tr>
      <td><strong>Typical Use</strong></td>
      <td>Vision, speech, language, search, embeddings</td>
      <td>Chatbots, coding assistants, reasoning, Q&amp;A</td>
    </tr>
    <tr>
      <td><strong>Output Style</strong></td>
      <td>Depends on task</td>
      <td>Sequential token generation</td>
    </tr>
    <tr>
      <td><strong>Examples</strong></td>
      <td>CLIP, DINO, Whisper, SAM</td>
      <td>GPT-4, LLaMA, Claude, Mistral</td>
    </tr>
  </tbody>
</table>

<p>Epochs – One epoch is one cycle through the entire dataset. Multiple intervals complete a batch, and multiple batches eventually complete an epoch. Multiple epochs are run until the accuracy of the model reaches an acceptable level, or when the error rate drops below an acceptable level.</p>

<p>Learning rate – The amount that values should be changed between epochs. As the model is refined, its internal weights are being nudged and error rates are checked to see if the model improves. A typical learning rate is 0.1 or 0.01, where 0.01 is a much smaller adjustment and could cause the training to take a long time to converge, whereas 0.1 is much larger and can cause the training to overshoot. It is one of the primary hyperparameters that you might adjust for training your model. Note that for text models, a much smaller learning rate (5e-5 for BERT) can result in a more accurate model.</p>

<p>Batch size – The number of records from the dataset that is to be selected for each interval to send to the GPUs for trainin</p>

<p>Transformer models use a self-attention mechanism and implement contextual embeddings</p>

<p>Transformer models are a type of neural network architecture designed to handle sequential data, such as language, in an efficient and scalable way. They rely on a mechanism called self-attention to process input data, allowing them to understand and generate language effectively. Self-attention allows the model to weigh the importance of different words in a sentence when encoding a particular word. This helps the model capture relationships and dependencies between words, regardless of their position in the sequence.</p>

<p>Transformer models use self-attention to weigh the importance of different words in a sentence, allowing them to capture complex dependencies. Positional encodings provide information about word order, and the encoder-decoder architecture enables effective processing and generation of sequences. This makes transformers highly effective for tasks like language translation, text generation, and more.</p>

<p>Temperature is a value between 0 and 1, and it regulates the creativity of the model’s responses. Use a lower temperature if you want more deterministic responses, and use a higher temperature if you want creative or different responses for the same prompt on Amazon Bedrock.</p>

<h2 id="llm">LLM</h2>

<p>On a high level how LLM works:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@startuml
title Chat-style LLM interaction (high level) with example + optional streaming

actor User
participant "Chat UI\n(Frontend)" as UI
participant "Controller\n(ChatGPT backend)" as C
participant "Tokenizer" as T
participant "LLM Model" as M
participant "Sampler\n(Top-P)" as S

User -&gt; UI: "Why is the sky blue?"
UI -&gt; C: raw text

C -&gt; T: tokenize(text)
T --&gt; C: prompt_token_ids

note over C
Tokenizer runs ONCE per user message.
The loop below is NOT "user asks again".
It is "generate ONE output token per iteration".
end note

loop generate answer token-by-token (many iterations)
  C -&gt; M: tokens_so_far
  M --&gt; C: next-token probabilities

  C -&gt; S: probabilities + top_p
  S --&gt; C: chosen next_token_id

  C -&gt; C: append chosen token to tokens_so_far

  opt streaming enabled
    C --&gt; UI: stream partial text\n(e.g. "Because sunlight...")
    UI --&gt; User: display partial text
  end

  note over C
  Stop when:
  - EOS token generated
  - stop sequence matched
  - max output tokens reached
  - user/app cancels
  end note
end

@enduml
</code></pre></div></div>

<p>Influences the percentage of most-likely candidates that the model considers for the next token</p>

<p>Top P represents the percentage of most likely candidates that the model considers for the next token. Choose a lower value to decrease the size of the pool and limit the options to more likely outputs. Choose a higher value to increase the size of the pool and allow the model to consider less likely outputs.</p>

<p>Using a RAG approach is the least costly and most efficient solution for providing up-to-date and relevant responses. In this approach, you convert all product catalog PDFs into a searchable knowledge base. When a customer query comes in, the RAG framework first retrieves the most relevant pieces of information from this knowledge base and then uses an LLM to generate a coherent response based on the retrieved context. This method does not require re-training the model or modifying every incoming query with large datasets, making it significantly more cost-effective. It ensures that the chatbot always has access to the most recent information without needing expensive updates or processing every time.</p>

<p>The company should use Domain Adaptation Fine-Tuning, which involves fine-tuning the model on domain-specific data to adapt its knowledge to that particular domain</p>

<p>Domain Adaptation Fine-Tuning is an effective approach because it takes a pre-trained Foundation Model and further adjusts its parameters using domain-specific data. This process helps the model learn the nuances, terminology, and context specific to the domain, enhancing its ability to generate accurate and relevant outputs in that field. Fine-tuning allows the model to specialize while retaining the general knowledge acquired during initial training.</p>

<p>The company should use Continued Pre-Training, which involves further training the model on a large corpus of domain-specific data, enhancing its ability to understand domain-specific terms, jargon, and context</p>

<p>Continued Pre-Training is another appropriate strategy for making a Foundation Model an expert in a specific domain. By pre-training the model on a large dataset specifically from the target domain, the model can learn the distinct characteristics, language patterns, and specialized knowledge relevant to that domain. This approach effectively builds upon the model’s existing knowledge, enhancing its domain expertise without starting training from scratch.</p>

<p>Bidirectional Encoder Representations from Transformers (BERT)</p>

<p>Embedding models are algorithms trained to encapsulate information into dense representations in a multi-dimensional space. Data scientists use embedding models to enable ML models to comprehend and reason with high-dimensional data.</p>

<p>BERT is the correct answer because it is specifically designed to capture the contextual meaning of words by looking at both the words that come before and after them (bidirectional context). Unlike older models that use static embeddings, BERT creates dynamic word embeddings that change depending on the surrounding text, allowing it to understand the different meanings of the same word in various contexts. This makes BERT ideal for tasks that require understanding the nuances and subtleties of language.</p>

<p>AWS AI Service
Transcribe
Comprehend
Recoknigtion</p>

    </article>
  </main>

  <div id="imageModal" class="image-modal">
  <div class="modal-content">
    <span class="modal-close">&times;</span>
    <button class="modal-nav modal-prev">&#8249;</button>
    <button class="modal-nav modal-next">&#8250;</button>
    <img id="modalImage" src="" alt="">
    <div id="modalCaption"></div>
  </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', () => {
  const modal = document.getElementById('imageModal');
  const modalImg = document.getElementById('modalImage');
  const modalCaption = document.getElementById('modalCaption');
  const modalClose = document.querySelector('.modal-close');
  const modalPrev = document.querySelector('.modal-prev');
  const modalNext = document.querySelector('.modal-next');

  const SCALE_STEP = 0.2;
  const MIN_SCALE = 1;
  const MAX_SCALE = 3;

  let modalImages = [];
  let currentIndex = -1;
  let currentScale = MIN_SCALE;
  let translateX = 0;
  let translateY = 0;
  let isDragging = false;
  let isTouchDragging = false;
  let isPinching = false;
  let dragStartX = 0;
  let dragStartY = 0;
  let pinchStartDistance = 0;
  let pinchStartScale = MIN_SCALE;
  let transitionTimeout;

  function refreshModalImages() {
    modalImages = Array.from(document.querySelectorAll('.modal-trigger'));
  }

  function applyTransform(withTransition = false) {
    if (currentScale <= MIN_SCALE) {
      currentScale = MIN_SCALE;
      translateX = 0;
      translateY = 0;
    }

    if (transitionTimeout) {
      clearTimeout(transitionTimeout);
      transitionTimeout = null;
    }

    modalImg.style.transition = withTransition ? 'transform 0.15s ease' : 'none';
    modalImg.style.transform = `translate(${translateX}px, ${translateY}px) scale(${currentScale})`;
    modalImg.style.cursor = currentScale > MIN_SCALE
      ? (isDragging || isTouchDragging ? 'grabbing' : 'grab')
      : 'auto';

    if (withTransition) {
      transitionTimeout = setTimeout(() => {
        modalImg.style.transition = 'none';
      }, 160);
    }
  }

  function resetTransform() {
    currentScale = MIN_SCALE;
    translateX = 0;
    translateY = 0;
    applyTransform(false);
  }

  function getDistance(touch1, touch2) {
    return Math.hypot(
      touch1.clientX - touch2.clientX,
      touch1.clientY - touch2.clientY
    );
  }

  function openModalAtIndex(index) {
    refreshModalImages();

    if (!modalImages.length) {
      return;
    }

    if (index < 0) {
      index = modalImages.length - 1;
    } else if (index >= modalImages.length) {
      index = 0;
    }

    const target = modalImages[index];
    if (!target) {
      return;
    }

    currentIndex = index;
    const src = target.dataset.modalSrc || target.src;
    const caption = target.getAttribute('data-caption') || target.alt;

    modalImg.src = src;
    modalCaption.textContent = caption || '';
    modal.classList.add('show');
    document.body.style.overflow = 'hidden';
    resetTransform();
  }

  function closeModal() {
    if (!modal.classList.contains('show')) {
      return;
    }
    modal.classList.remove('show');
    document.body.style.overflow = '';
    currentIndex = -1;
    isDragging = false;
    isTouchDragging = false;
    isPinching = false;
    resetTransform();
  }

  refreshModalImages();

  modalImg.addEventListener('dragstart', event => event.preventDefault());

  document.addEventListener('click', event => {
    const trigger = event.target.closest('.modal-trigger');
    if (!trigger) {
      return;
    }

    event.preventDefault();
    refreshModalImages();
    const index = modalImages.indexOf(trigger);
    openModalAtIndex(index > -1 ? index : 0);
  });

  modalClose?.addEventListener('click', closeModal);

  modal.addEventListener('click', event => {
    if (event.target === modal) {
      closeModal();
    }
  });

  document.addEventListener('keydown', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    switch (event.key) {
      case 'Escape':
        closeModal();
        break;
      case 'ArrowLeft':
        event.preventDefault();
        openModalAtIndex(currentIndex - 1);
        break;
      case 'ArrowRight':
        event.preventDefault();
        openModalAtIndex(currentIndex + 1);
        break;
      case '+':
      case '=':
        event.preventDefault();
        currentScale = Math.min(MAX_SCALE, currentScale + SCALE_STEP);
        applyTransform(true);
        break;
      case '-':
        event.preventDefault();
        currentScale = Math.max(MIN_SCALE, currentScale - SCALE_STEP);
        applyTransform(true);
        break;
      case '0':
        event.preventDefault();
        resetTransform();
        applyTransform(true);
        break;
      default:
        break;
    }
  });

  modal.addEventListener('wheel', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    event.preventDefault();
    const delta = event.deltaY > 0 ? -SCALE_STEP : SCALE_STEP;
    const nextScale = Math.max(MIN_SCALE, Math.min(MAX_SCALE, currentScale + delta));

    if (nextScale === currentScale) {
      return;
    }

    currentScale = nextScale;
    applyTransform(true);
  }, { passive: false });

  if (modalPrev) {
    modalPrev.addEventListener('click', event => {
      event.preventDefault();
      if (currentIndex === -1) {
        return;
      }
      openModalAtIndex(currentIndex - 1);
    });
  }

  if (modalNext) {
    modalNext.addEventListener('click', event => {
      event.preventDefault();
      if (currentIndex === -1) {
        return;
      }
      openModalAtIndex(currentIndex + 1);
    });
  }

  modalImg.addEventListener('mousedown', event => {
    if (!modal.classList.contains('show') || currentScale <= MIN_SCALE) {
      return;
    }

    event.preventDefault();
    isDragging = true;
    dragStartX = event.clientX;
    dragStartY = event.clientY;
    modalImg.style.cursor = 'grabbing';
  });

  document.addEventListener('mousemove', event => {
    if (!isDragging) {
      return;
    }

    event.preventDefault();
    translateX += event.clientX - dragStartX;
    translateY += event.clientY - dragStartY;
    dragStartX = event.clientX;
    dragStartY = event.clientY;
    applyTransform(false);
  });

  document.addEventListener('mouseup', () => {
    if (!isDragging) {
      return;
    }
    isDragging = false;
    modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
  });

  modalImg.addEventListener('touchstart', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.touches.length === 1 && currentScale > MIN_SCALE) {
      event.preventDefault();
      isTouchDragging = true;
      dragStartX = event.touches[0].clientX;
      dragStartY = event.touches[0].clientY;
      modalImg.style.cursor = 'grabbing';
    } else if (event.touches.length === 2) {
      event.preventDefault();
      isTouchDragging = false;
      isPinching = true;
      pinchStartDistance = getDistance(event.touches[0], event.touches[1]);
      pinchStartScale = currentScale;
      modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
    }
  }, { passive: false });

  modalImg.addEventListener('touchmove', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (isPinching && event.touches.length === 2) {
      event.preventDefault();
      const distance = getDistance(event.touches[0], event.touches[1]);
      if (pinchStartDistance > 0) {
        const scaleRatio = distance / pinchStartDistance;
        currentScale = Math.max(MIN_SCALE, Math.min(MAX_SCALE, pinchStartScale * scaleRatio));
        applyTransform(false);
      }
    } else if (isTouchDragging && event.touches.length === 1) {
      event.preventDefault();
      translateX += event.touches[0].clientX - dragStartX;
      translateY += event.touches[0].clientY - dragStartY;
      dragStartX = event.touches[0].clientX;
      dragStartY = event.touches[0].clientY;
      applyTransform(false);
    }
  }, { passive: false });

  modalImg.addEventListener('touchend', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.touches.length === 0) {
      isTouchDragging = false;
      modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
    }

    if (event.touches.length < 2) {
      isPinching = false;
      pinchStartDistance = 0;
      pinchStartScale = currentScale;
    }
  });

  modalImg.addEventListener('touchcancel', () => {
    if (!modal.classList.contains('show')) {
      return;
    }

    isTouchDragging = false;
    isPinching = false;
    pinchStartDistance = 0;
    pinchStartScale = currentScale;
    modalImg.style.cursor = currentScale > MIN_SCALE ? 'grab' : 'auto';
  });

  modal.addEventListener('touchend', event => {
    if (!modal.classList.contains('show')) {
      return;
    }

    if (event.target === modal && event.changedTouches.length === 1 && !isTouchDragging && !isPinching) {
      closeModal();
    }
  }, { passive: true });
});
</script>

<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('[data-snippet-id]').forEach(caption => {
    const snippetId = caption.getAttribute('data-snippet-id');
    const snippetElement = document.getElementById(snippetId);

    if (snippetElement) {
      const content = snippetElement.textContent.replace(/"/g, '&quot;');
      caption.setAttribute('data-tooltip', content);
      caption.classList.add('diagram-caption');
    }
  });
});
</script>


  <!-- Floating Table of Contents -->
  <div id="floating-toc" class="floating-toc">
    <div class="toc-icon">
      <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
        <line x1="8" y1="6" x2="21" y2="6"></line>
        <line x1="8" y1="12" x2="21" y2="12"></line>
        <line x1="8" y1="18" x2="21" y2="18"></line>
        <line x1="3" y1="6" x2="3.01" y2="6"></line>
        <line x1="3" y1="12" x2="3.01" y2="12"></line>
        <line x1="3" y1="18" x2="3.01" y2="18"></line>
      </svg>
    </div>
    <div class="toc-content">
      <div class="toc-header">
        <span>Contents</span>
        <button class="toc-close" aria-label="Close table of contents">
          <svg width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <line x1="18" y1="6" x2="6" y2="18"></line>
            <line x1="6" y1="6" x2="18" y2="18"></line>
          </svg>
        </button>
      </div>
      <nav class="toc-nav" id="toc-nav">
        <!-- Generated by JavaScript -->
      </nav>
    </div>
  </div>

  <footer class="site-footer">
    <span>© 2026 glucolte • </span>
    <a href="https://github.com/gLuColte/glucolte.github.io">source</a>
  </footer>

  <script>
    // Dark mode functionality
    function initDarkMode() {
      const toggle = document.getElementById('dark-mode-toggle');
      const body = document.body;
      
      // Check for saved theme preference or default to light mode
      const savedTheme = localStorage.getItem('theme');
      const prefersDark = window.matchMedia('(prefers-color-scheme: dark)').matches;
      
      if (savedTheme === 'dark' || (!savedTheme && prefersDark)) {
        body.setAttribute('data-theme', 'dark');
      }
      
      // Toggle dark mode
      if (toggle) {
        toggle.addEventListener('click', function() {
          const currentTheme = body.getAttribute('data-theme');
          const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
          
          body.setAttribute('data-theme', newTheme);
          localStorage.setItem('theme', newTheme);
        });
      }
    }
    
    // Initialize dark mode immediately to prevent flash
    initDarkMode();
    
    // Initialize highlight.js and floating TOC after the DOM is loaded
    document.addEventListener('DOMContentLoaded', function() {
      hljs.highlightAll();
      
      // Floating TOC functionality - only show on sub-study pages
      const floatingToc = document.getElementById('floating-toc');
      const tocNav = document.getElementById('toc-nav');
      const tocClose = document.querySelector('.toc-close');
      
      // Check if we're on a sub-study page (not the main study index)
      const isSubStudyPage = window.location.pathname !== '/study/' && 
                            window.location.pathname !== '/study' && 
                            window.location.pathname.startsWith('/study/');
      
      if (floatingToc && tocNav && isSubStudyPage) {
        // Generate TOC from headings
        function generateTOC() {
          const headings = document.querySelectorAll('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6');
          if (headings.length === 0) {
            floatingToc.style.display = 'none';
            return;
          }
          
          const tocList = document.createElement('ul');
          let currentLevel = 0;
          let currentList = tocList;
          const listStack = [tocList];
          
          headings.forEach((heading, index) => {
            const level = parseInt(heading.tagName.charAt(1));
            const id = heading.id || `heading-${index}`;
            
            // Ensure heading has an ID
            if (!heading.id) {
              heading.id = id;
            }
            
            // Create list item
            const listItem = document.createElement('li');
            const link = document.createElement('a');
            link.href = `#${id}`;
            link.textContent = heading.textContent.trim();
            link.addEventListener('click', function(e) {
              e.preventDefault();
              const targetElement = document.getElementById(id);
              if (targetElement) {
                targetElement.scrollIntoView({ behavior: 'smooth', block: 'start' });
                // Close TOC after clicking
                floatingToc.classList.remove('toc-open');
              }
            });
            
            listItem.appendChild(link);
            
            // Handle nesting
            if (level > currentLevel) {
              // Go deeper
              for (let i = currentLevel; i < level; i++) {
                const newList = document.createElement('ul');
                currentList.appendChild(newList);
                listStack.push(newList);
                currentList = newList;
              }
            } else if (level < currentLevel) {
              // Go shallower
              for (let i = currentLevel; i > level; i--) {
                listStack.pop();
                currentList = listStack[listStack.length - 1];
              }
            }
            
            currentList.appendChild(listItem);
            currentLevel = level;
          });
          
          tocNav.appendChild(tocList);
        }
        
        // Generate the TOC
        generateTOC();
        
        // Handle close button
        if (tocClose) {
          tocClose.addEventListener('click', function() {
            floatingToc.classList.remove('toc-open');
          });
        }
        
        // Handle click on icon to toggle
        const tocIcon = document.querySelector('.toc-icon');
        if (tocIcon) {
          tocIcon.addEventListener('click', function() {
            floatingToc.classList.toggle('toc-open');
          });
        }
        
        // Active section highlighting
        function updateActiveSection() {
          const headings = document.querySelectorAll('.content h1, .content h2, .content h3, .content h4, .content h5, .content h6');
          const tocLinks = tocNav.querySelectorAll('a');
          
          // Remove active class from all links
          tocLinks.forEach(link => link.classList.remove('active'));
          
          // Find the current section
          let currentHeading = null;
          const scrollPosition = window.scrollY + 100; // Offset for better UX
          
          for (let i = headings.length - 1; i >= 0; i--) {
            const heading = headings[i];
            const headingTop = heading.offsetTop;
            
            if (headingTop <= scrollPosition) {
              currentHeading = heading;
              break;
            }
          }
          
          // Add active class to current section
          if (currentHeading) {
            const activeLink = tocNav.querySelector(`a[href="#${currentHeading.id}"]`);
            if (activeLink) {
              activeLink.classList.add('active');
            }
          }
        }
        
        // Update active section on scroll
        let scrollTimeout;
        window.addEventListener('scroll', function() {
          if (scrollTimeout) {
            clearTimeout(scrollTimeout);
          }
          scrollTimeout = setTimeout(updateActiveSection, 10);
        });
        
        // Initial update
        updateActiveSection();
      } else if (floatingToc && !isSubStudyPage) {
        // Hide floating TOC on main study page
        floatingToc.style.display = 'none';
      }
      
      // Legacy TOC functionality (for existing markdown TOCs)
      const toc = document.querySelector('#markdown-toc');
      if (toc) {
        // Hide the floating TOC if there's already a markdown TOC
        if (floatingToc) {
          floatingToc.style.display = 'none';
        }
        
        // Create TOC container with header
        const tocContainer = document.createElement('div');
        tocContainer.className = 'toc-container';
        tocContainer.style.cssText = `
          background: #f8fafc;
          border: 1px solid #e5e7eb;
          border-radius: 8px;
          padding: 16px;
          margin: 20px 0;
          position: relative;
        `;
        
        // Add TOC header
        const tocHeader = document.createElement('h3');
        tocHeader.textContent = 'Table of Contents';
        tocHeader.style.cssText = `
          margin: 0 0 12px 0;
          font-size: 16px;
          font-weight: 600;
          color: #374151;
        `;
        
        // Add back to top button
        const backToTopBtn = document.createElement('button');
        backToTopBtn.textContent = '↑ Top';
        backToTopBtn.style.cssText = `
          position: absolute;
          top: 12px;
          right: 12px;
          background: #ffffff;
          border: 1px solid #d1d5db;
          border-radius: 6px;
          padding: 4px 8px;
          font-size: 12px;
          cursor: pointer;
          color: #6b7280;
          transition: all 0.2s ease;
        `;
        
        // Add hover effect for back to top button
        backToTopBtn.addEventListener('mouseenter', function() {
          this.style.background = '#f3f4f6';
          this.style.color = '#374151';
        });
        
        backToTopBtn.addEventListener('mouseleave', function() {
          this.style.background = '#ffffff';
          this.style.color = '#6b7280';
        });
        
        // Back to top functionality
        backToTopBtn.addEventListener('click', function() {
          window.scrollTo({ top: 0, behavior: 'smooth' });
        });
        
        // Style the TOC list
        toc.style.cssText = `
          margin: 0;
          padding: 0;
          font-size: 14px;
          line-height: 1.5;
        `;
        
        // Insert header and button into container
        tocContainer.appendChild(tocHeader);
        tocContainer.appendChild(backToTopBtn);
        tocContainer.appendChild(toc);
        
        // Replace the original TOC with the new container
        toc.parentNode.insertBefore(tocContainer, toc);
        tocContainer.appendChild(toc);
        
        // Add smooth scrolling to TOC links
        const tocLinks = toc.querySelectorAll('a');
        tocLinks.forEach(link => {
          link.addEventListener('click', function(e) {
            e.preventDefault();
            const targetId = this.getAttribute('href').substring(1);
            const targetElement = document.getElementById(targetId);
            if (targetElement) {
              targetElement.scrollIntoView({ behavior: 'smooth' });
            }
          });
        });
      }
    });
  </script>
</body>
</html>
